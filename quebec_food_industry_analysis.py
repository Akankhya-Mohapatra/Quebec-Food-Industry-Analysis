# -*- coding: utf-8 -*-
"""Quebec_Food_Industry_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1himgNimbt3O5TJSWibGHT9SOrl_yiNY7
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.colors as colors
import requests
import io
import folium
import geopy
import json
from geopy.geocoders import Nominatim
from sklearn.cluster import KMeans

"""#### Let' scrape a wikipedia page (which needs serious donations, please donate) to get the list of towns in Quebec

![Wikipedia logo](https://upload.wikimedia.org/wikipedia/commons/7/77/Wikipedia_svg_logo.svg)
"""

tables=pd.read_html("https://en.wikipedia.org/wiki/List_of_towns_in_Quebec")

tables1=tables[1]
tables1

df=tables1.loc[:,['Name','Region']]
df

df.isna().any().any() #missing values present or not

df.isna().sum().sum() #total no of missing values

df.isna().sum()/(len(df))*100 #missing values percentage

df.loc[:, df.isnull().any()].columns #determining columns with missing values

df.isna().sum()/(len(df))*100 #no of missing values in df_town

#determining values with [] in Name column
print(df[df.Name.str.endswith("]")])
#rows with ___ in Region column
print(df.loc[215:224 , :])
#removing the columns
df=df.drop([81,96,116,141,224])

#reorder index after removing columns
df_town=df
df_town.reset_index(drop=True, inplace=True) 
df_town.loc[78:220 , :]

"""#### Let's get the geographical location of the towns

"""

count=df_town.index
print(count)

#FOR FULL DATA (220 ROWS)
town_latitude=[0 for a in range(220)]
town_longitude=[0 for a in range(220)]
for i in list(range(220)):
  address = df_town.loc[i,"Name"]+", "+df_town.loc[i,"Region"]+", Quebec"
  locator = Nominatim(user_agent="quebec_explore")
  location = locator.geocode(address)
  town_latitude[i]=location.latitude
  town_longitude[i]=location.longitude

print(town_latitude)
print(town_longitude)

df_town['Latitude']=town_latitude
df_town

df_town['Longitude']=town_longitude
df_town

#creating bag of words model 
BOW = df_town.iloc[1:, :].values 
print(BOW[:])

"""#### Now let's plot the cities in a map of Canada"""

Quebec_lat=48.571852
Quebec_lng=-79.201022

map_Quebec = folium.Map(location=[Quebec_lat, Quebec_lng], zoom_start=6)

for lat, lng, town, reg in zip(df_town['Latitude'], df_town['Longitude'], df_town['Name'],df_town['Region']):
    label='{}, {}'.format(town, reg)
    folium.Marker(location=[lat,lng]).add_to(map_Quebec)

map_Quebec

CLIENT_ID = '****'
CLIENT_SECRET = '****'
VERSION='20180325'
LIMIT=5000
RADIUS=5000

url='https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&ll={},{}&v={}&limit={}&radius={}'.format(CLIENT_ID,CLIENT_SECRET,df_town.loc[0,"Latitude"],
                                                                                            df_town.loc[0,"Longitude"],VERSION,LIMIT,RADIUS)

result=requests.get(url).json()
result

LIMIT=400
def getNearbyVenues(names, latitudes, longitudes, radius=2000):
    venues_list=[]
    for name, lat, lng in zip(names, latitudes, longitudes):
      print(name)
      url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(
            CLIENT_ID, 
            CLIENT_SECRET, 
            VERSION, 
            lat, 
            lng, 
            radius, 
            LIMIT)
      try:
            results=requests.get(url).json()['response']['groups'][0]['items']
      except:
        continue;
        venues_list.append([(
        name, 
        lat, 
        lng,
        v['venue']['name'],
        v['venue']['location']['lat'],
        v['venue']['location']['lng'],
        v['venue']['categories'][0]['name']) for v in results])
        
    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])
    nearby_venues.columns = ['Neighborhood', 
                  'Neighborhood Latitude', 
                  'Neighborhood Longitude', 
                  'Venue', 
                  'Venue Latitude', 
                  'Venue Longitude', 
                  'Venue Category']
    
    return(nearby_venues)

"""#### Let's get all the venues in the towns of Quebec"""

Quebec_venues = getNearbyVenues(names=df_town['Name'],latitudes=df_town['Latitude'],longitudes=df_town['Longitude'])

Quebec_venues

Quebec_venues.groupby("Neighborhood").count()

Quebec_venues.groupby("Venue Category").count()

#One hot encoding of categorical features 
Quebec_onehot=pd.get_dummies(Quebec_venues[['Venue Category']], prefix_sep="")
#Quebec_onehot.drop("Neighborhood", axis=1, inplace=True)
Quebec_onehot['Neighborhood']=Quebec_venues['Neighborhood']

fixed_columns=[Quebec_onehot.columns[-1]]+list(Quebec_onehot.columns[:-1])
Quebec_onehot=Quebec_onehot[fixed_columns]
Quebec_onehot

#re-ordering indexes
Quebec_grouped=Quebec_onehot.groupby("Neighborhood").mean().reset_index()
Quebec_grouped

def top_common_venues(row, num_top_venues):
    row_categories = row.iloc[1:]
    row_categories_sorted = row_categories.sort_values(ascending=False)
    
    return row_categories_sorted.index.values[0:num_top_venues]

"""#### Let's find the top 10 venues in every neighborhood"""

num_top_venues = 10
indicators = ['st', 'nd', 'rd']

columns = ['Neighborhood']
for point in np.arange(num_top_venues):
    try:
        columns.append('{}{} Most Common Venue'.format(point+1, indicators[point]))
    except:
        columns.append('{}th Most Common Venue'.format(point+1))

neighborhoods_venues_sorted = pd.DataFrame(columns=columns)
neighborhoods_venues_sorted['Neighborhood'] = Quebec_grouped['Neighborhood']

for point in np.arange(Quebec_grouped.shape[0]):
    neighborhoods_venues_sorted.iloc[point, 1:] = top_common_venues(Quebec_grouped.iloc[point, :], num_top_venues)

neighborhoods_venues_sorted

"""#### Let's cluster the neighborhoods"""

kclusters = 3

Quebec_grouped_clustering = Quebec_grouped.drop('Neighborhood', 1)
kmeans = KMeans(n_clusters=kclusters, random_state=1234).fit(Quebec_grouped_clustering)

display(kmeans.cluster_centers_)

df_town.drop('Region',axis=1,inplace=True)

df_town.rename(columns={"Name":"Neighborhood"}, inplace=True)
df_town

neighborhoods_venues_sorted.drop('Cluster Labels', axis=1, inplace=True)

"""#### Let's merge the main dataset with the most common venues"""

neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_.astype('int32'))
neighborhoods_venues_sorted["Cluster Labels"].dtype
Quebec_merged = df_town

Quebec_merged = Quebec_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')
print(Quebec_merged.shape)

Quebec_merged.reset_index(inplace=True)
Quebec_merged.drop("index",inplace=True, axis=1)
Quebec_merged

Quebec_merged.dropna()

#checking missing values
Quebec_merged = Quebec_merged[~Quebec_merged['Cluster Labels'].isnull()]
Quebec_merged.shape

"""#### Now let's plot the areas in map with a colour assigned to each cluster"""

latitude=45.647156
longitude=-72.565411

map_clusters = folium.Map(location=[latitude, longitude], zoom_start=6)

arg = np.arange(kclusters)
rg = [i + arg + (i*arg)**2 for i in range(kclusters)]
col_array = cm.rainbow(np.linspace(0, 1, len(rg)))
rainbow = [colors.rgb2hex(i) for i in col_array]

# add markers to the map
markers_colors = []
for lat, lng, ngh, cluster in zip(Quebec_merged['Latitude'], Quebec_merged['Longitude'], Quebec_merged['Neighborhood'], Quebec_merged['Cluster Labels']):
    label = folium.Popup(str(ngh) + ' Cluster ' + str(cluster), parse_html=True)
    folium.CircleMarker(
        [lat, lng],
        radius=5,
        popup=label,
        fill=True,
        color=rainbow[int(cluster)-1],
        fill_color=rainbow[int(cluster)-1],
        fill_opacity=0.7).add_to(map_clusters)
       
map_clusters

cluster_1=Quebec_merged[Quebec_merged.loc[:,"Cluster Labels"]==0.0].reset_index(drop=True)
cluster_1

cluster_2=Quebec_merged[Quebec_merged.loc[:,"Cluster Labels"]==1.0].reset_index(drop=True)
cluster_2

cluster_3=Quebec_merged[Quebec_merged.loc[:,"Cluster Labels"]==2.0].reset_index(drop=True)
cluster_3

"""### Let's analyze the two clusters"""

cluster_1.groupby("1st Most Common Venue").count().sort_values(by="Neighborhood",ascending=False)

"""#### The most frequent "1st most common venue in first cluster is Grocery Store" followed by "Fast Food restaurant" and "Liquor Store". This is also the similar to findings in 2nd most common venues too"""

cluster_1.groupby("2nd Most Common Venue").count().sort_values(by="Neighborhood",ascending=False)

"""#### Gym and Fitness Center and shopping malls are also popular in cluster 1"""

cluster_1.groupby("6th Most Common Venue").count().sort_values(by="Neighborhood",ascending=False)

"""#### Fireworks Store and Fish & Chips Shops seems to have taken 10th most frequent available places in Quebec

### Now let's see the most frequent top venues in the second cluster
"""

cluster_2.groupby("1st Most Common Venue").count().sort_values(by="Neighborhood",ascending=False)

"""###### Construction and Landscaping, ATMs are the also among the available venues in cluster 2

#### Filipino restaurants are also preferable venue in cluster 2
"""

cluster_2.groupby("10th Most Common Venue").count().sort_values(by="Neighborhood",ascending=False)

"""#### Hotel Bar and Zoo are also among the most available venues in cluster 2

Now let's see the most frequent top venues in the third cluster
"""

cluster_3.groupby("1st Most Common Venue").count().sort_values(by="Neighborhood",ascending=False)

cluster_3.groupby("10th Most Common Venue").count().sort_values(by="Neighborhood",ascending=False)

"""###### Farms and Bakery are among available places in cluster 3. Airport Terminal, Museum, Night Club and Hockey Arena are also some of the most common venues in Cluster 3.

###CLUSTER PLOT

## Final Suggestion: Any investment other than Fast Food restaurant, Grocery Store and Coffee Shop is better, considering there's a market for it. Bus Station, Shopping Malls and Beach are lagging behind in the frequency. So investing in them would make a better sense as there's a market for it but the availability is lesser.
"""